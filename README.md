## Astronomer DAG authoring workshop

Getting started with Airflow, the de facto standard for data orchestration with over 12M downloads per month, has never been easier. With a combination of new Airflow features, open source community projects, and Astro products, you can create complex data pipelines that leverage Airflow’s best-in-class orchestration while writing less code and without extensive Airflow knowledge.

This repo supports a public workshop where you'll learn how to use Airflow and the Astro Cloud IDE. In just a couple of hours, you’ll learn:

- How to write a basic Airflow pipeline using common operators.
- How to use Airflow connections and variables.
- How to write an ELT DAG that implements SQL and Python functions with no boilerplate code using the Astro Python SDK, a new open source SDK designed for rapid development of ETL/ELT workflows.
- How Astronomer is making DAG writing easier, including the [Astro Cloud IDE](https://docs.astronomer.io/astro/cloud-ide), a notebook-inspired way to write data pipelines.

Instructions for Parts 1-2 of the workshop can be found in the `include/workshop-instructions/` directory. Both parts require access to the Astro Cloud IDE. A [free trial](https://www.astronomer.io/try-astro/) is available. 

This workshop is intended to be completed during a live event conducted by Astronomer.
